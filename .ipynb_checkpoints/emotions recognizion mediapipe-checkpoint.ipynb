{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21f3473a",
   "metadata": {},
   "source": [
    "# install and import dependencies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cdcf8c4b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mediapipe\n",
      "  Downloading mediapipe-0.10.21-cp312-cp312-macosx_11_0_universal2.whl.metadata (9.9 kB)\n",
      "Requirement already satisfied: opencv-python in /opt/anaconda3/envs/dnn/lib/python3.12/site-packages (4.11.0.86)\n",
      "Requirement already satisfied: pandas in /opt/anaconda3/envs/dnn/lib/python3.12/site-packages (2.2.3)\n",
      "Requirement already satisfied: scikit-learn in /opt/anaconda3/envs/dnn/lib/python3.12/site-packages (1.6.1)\n",
      "Requirement already satisfied: absl-py in /opt/anaconda3/envs/dnn/lib/python3.12/site-packages (from mediapipe) (2.1.0)\n",
      "Requirement already satisfied: attrs>=19.1.0 in /opt/anaconda3/envs/dnn/lib/python3.12/site-packages (from mediapipe) (24.3.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in /opt/anaconda3/envs/dnn/lib/python3.12/site-packages (from mediapipe) (25.2.10)\n",
      "Collecting jax (from mediapipe)\n",
      "  Downloading jax-0.5.0-py3-none-any.whl.metadata (22 kB)\n",
      "Collecting jaxlib (from mediapipe)\n",
      "  Downloading jaxlib-0.5.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (978 bytes)\n",
      "Requirement already satisfied: matplotlib in /opt/anaconda3/envs/dnn/lib/python3.12/site-packages (from mediapipe) (3.10.0)\n",
      "Collecting numpy<2 (from mediapipe)\n",
      "  Downloading numpy-1.26.4-cp312-cp312-macosx_11_0_arm64.whl.metadata (61 kB)\n",
      "Collecting opencv-contrib-python (from mediapipe)\n",
      "  Downloading opencv_contrib_python-4.11.0.86-cp37-abi3-macosx_13_0_arm64.whl.metadata (20 kB)\n",
      "Collecting protobuf<5,>=4.25.3 (from mediapipe)\n",
      "  Downloading protobuf-4.25.6-cp37-abi3-macosx_10_9_universal2.whl.metadata (541 bytes)\n",
      "Collecting sounddevice>=0.4.4 (from mediapipe)\n",
      "  Downloading sounddevice-0.5.1-py3-none-macosx_10_6_x86_64.macosx_10_6_universal2.whl.metadata (1.4 kB)\n",
      "Collecting sentencepiece (from mediapipe)\n",
      "  Downloading sentencepiece-0.2.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (7.7 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/envs/dnn/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/envs/dnn/lib/python3.12/site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/envs/dnn/lib/python3.12/site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /opt/anaconda3/envs/dnn/lib/python3.12/site-packages (from scikit-learn) (1.15.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/anaconda3/envs/dnn/lib/python3.12/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/anaconda3/envs/dnn/lib/python3.12/site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/envs/dnn/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: CFFI>=1.0 in /opt/anaconda3/envs/dnn/lib/python3.12/site-packages (from sounddevice>=0.4.4->mediapipe) (1.17.1)\n",
      "Requirement already satisfied: ml_dtypes>=0.4.0 in /opt/anaconda3/envs/dnn/lib/python3.12/site-packages (from jax->mediapipe) (0.4.1)\n",
      "Requirement already satisfied: opt_einsum in /opt/anaconda3/envs/dnn/lib/python3.12/site-packages (from jax->mediapipe) (3.4.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/anaconda3/envs/dnn/lib/python3.12/site-packages (from matplotlib->mediapipe) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/anaconda3/envs/dnn/lib/python3.12/site-packages (from matplotlib->mediapipe) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/anaconda3/envs/dnn/lib/python3.12/site-packages (from matplotlib->mediapipe) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/anaconda3/envs/dnn/lib/python3.12/site-packages (from matplotlib->mediapipe) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/envs/dnn/lib/python3.12/site-packages (from matplotlib->mediapipe) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in /opt/anaconda3/envs/dnn/lib/python3.12/site-packages (from matplotlib->mediapipe) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/anaconda3/envs/dnn/lib/python3.12/site-packages (from matplotlib->mediapipe) (3.2.1)\n",
      "Requirement already satisfied: pycparser in /opt/anaconda3/envs/dnn/lib/python3.12/site-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.21)\n",
      "Downloading mediapipe-0.10.21-cp312-cp312-macosx_11_0_universal2.whl (49.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.2/49.2 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "Downloading numpy-1.26.4-cp312-cp312-macosx_11_0_arm64.whl (13.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.7/13.7 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading protobuf-4.25.6-cp37-abi3-macosx_10_9_universal2.whl (394 kB)\n",
      "Downloading sounddevice-0.5.1-py3-none-macosx_10_6_x86_64.macosx_10_6_universal2.whl (107 kB)\n",
      "Downloading jax-0.5.0-py3-none-any.whl (2.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "Downloading jaxlib-0.5.0-cp312-cp312-macosx_11_0_arm64.whl (79.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.2/79.2 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading opencv_contrib_python-4.11.0.86-cp37-abi3-macosx_13_0_arm64.whl (46.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.3/46.3 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "Downloading sentencepiece-0.2.0-cp312-cp312-macosx_11_0_arm64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "Installing collected packages: sentencepiece, protobuf, numpy, sounddevice, opencv-contrib-python, jaxlib, jax, mediapipe\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 5.29.3\n",
      "    Uninstalling protobuf-5.29.3:\n",
      "      Successfully uninstalled protobuf-5.29.3\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.0.2\n",
      "    Uninstalling numpy-2.0.2:\n",
      "      Successfully uninstalled numpy-2.0.2\n",
      "Successfully installed jax-0.5.0 jaxlib-0.5.0 mediapipe-0.10.21 numpy-1.26.4 opencv-contrib-python-4.11.0.86 protobuf-4.25.6 sentencepiece-0.2.0 sounddevice-0.5.1\n"
     ]
    }
   ],
   "source": [
    "#!pip install mediapipe opencv-python pandas scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d83b7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp \n",
    "import cv2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "570b3cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_drawing = mp.solutions.drawing_utils # Drawing helpers\n",
    "mp_holistic = mp.solutions.holistic # Mediapipe Solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c30cb3",
   "metadata": {},
   "source": [
    "# Make some detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f6a85a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1740235182.447219 11983082 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 88.1), renderer: Apple M1\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "W0000 00:00:1740235182.556307 11983859 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1740235182.575105 11983865 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1740235182.579415 11983861 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1740235182.579673 11983864 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1740235182.579788 11983866 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1740235182.592337 11983864 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1740235182.599023 11983866 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1740235182.599556 11983861 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1740235182.608657 11983860 landmark_projection_calculator.cc:186] Using NORM_RECT without IMAGE_DIMENSIONS is only supported for the square ROI. Provide IMAGE_DIMENSIONS or use PROJECTION_MATRIX.\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "# Initiate holistic model\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        # Recolor Feed\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False        \n",
    "        \n",
    "        # Make Detections\n",
    "        results = holistic.process(image)\n",
    "#         print(results.face_landmarks)\n",
    "        \n",
    "        # face_landmarks, pose_landmarks, left_hand_landmarks, right_hand_landmarks\n",
    "        \n",
    "        # Recolor image back to BGR for rendering\n",
    "        image.flags.writeable = True   \n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        # 1. Draw face landmarks\n",
    "        mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACEMESH_CONTOURS, \n",
    "                                 mp_drawing.DrawingSpec(color=(80,110,10), thickness=1, circle_radius=1),\n",
    "                                 mp_drawing.DrawingSpec(color=(80,256,121), thickness=1, circle_radius=1)\n",
    "                                 )\n",
    "        \n",
    "        # 2. Right hand\n",
    "        mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                                 mp_drawing.DrawingSpec(color=(80,22,10), thickness=2, circle_radius=4),\n",
    "                                 mp_drawing.DrawingSpec(color=(80,44,121), thickness=2, circle_radius=2)\n",
    "                                 )\n",
    "\n",
    "        # 3. Left Hand\n",
    "        mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                                 mp_drawing.DrawingSpec(color=(121,22,76), thickness=2, circle_radius=4),\n",
    "                                 mp_drawing.DrawingSpec(color=(121,44,250), thickness=2, circle_radius=2)\n",
    "                                 )\n",
    "\n",
    "        # 4. Pose Detections\n",
    "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS, \n",
    "                                 mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=4),\n",
    "                                 mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)\n",
    "                                 )\n",
    "                        \n",
    "        cv2.imshow('Raw Webcam Feed', image)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a144b338",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.face_landmarks.landmark[0].visibility"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5623d659",
   "metadata": {},
   "source": [
    "# Capture Landmarks & Export to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c9395fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "888af34e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "501"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_coords = len(results.pose_landmarks.landmark)+len(results.face_landmarks.landmark)\n",
    "num_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5da374cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "landmarks = ['class']\n",
    "for val in range(1, num_coords+1):\n",
    "    landmarks += ['x{}'.format(val), 'y{}'.format(val), 'z{}'.format(val), 'v{}'.format(val)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "096a4798",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['class', 'x1', 'y1', 'z1', 'v1', 'x2']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "landmarks[0:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "200db860",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('coords.csv', mode='w', newline='') as f:\n",
    "    csv_writer = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    csv_writer.writerow(landmarks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aca3b5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_name = \"happy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "699718da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1740235231.153057 11983082 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 88.1), renderer: Apple M1\n",
      "W0000 00:00:1740235231.261321 11985276 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1740235231.286013 11985276 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1740235231.288357 11985275 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1740235231.288375 11985274 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1740235231.288430 11985277 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1740235231.317848 11985275 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1740235231.331921 11985274 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1740235231.333015 11985277 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        #Recoloring the Feed\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False\n",
    "        \n",
    "        #Making Detections\n",
    "        results = holistic.process(image)\n",
    "\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        #1. Drawing face landmarks\n",
    "        mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACEMESH_TESSELATION,\n",
    "                                  mp_drawing.DrawingSpec(color=(80,110,10), thickness=1, circle_radius=1),\n",
    "                                  mp_drawing.DrawingSpec(color=(80,256,121), thickness=1, circle_radius=1)\n",
    "                                  )\n",
    "\n",
    "        #2. Right Hand\n",
    "        mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
    "                                  mp_drawing.DrawingSpec(color=(80,22,10), thickness=2, circle_radius=4),\n",
    "                                  mp_drawing.DrawingSpec(color=(80,44,121), thickness=2, circle_radius=2)\n",
    "                                  )\n",
    "        #3. Left Hand\n",
    "        mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
    "                                  mp_drawing.DrawingSpec(color=(121,22,76), thickness=2, circle_radius=4),\n",
    "                                  mp_drawing.DrawingSpec(color=(121,44,250), thickness=2, circle_radius=2)\n",
    "                                  )\n",
    "        #4. Pose Detections\n",
    "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS,\n",
    "                                  mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=4),\n",
    "                                  mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)\n",
    "                                  )\n",
    "        \n",
    "        #Export Coordinates\n",
    "        try:\n",
    "            #Extracting Pose Landmarks\n",
    "            pose = results.pose_landmarks.landmark\n",
    "            pose_row = list(np.array([[landmark.x, landmark.y, landmark.z, landmark.visibility] for landmark in pose]).flatten())\n",
    "\n",
    "            #Extracting Face Landmarks\n",
    "            face = results.face_landmarks.landmark\n",
    "            face_row = list(np.array([[landmark.x, landmark.y, landmark.z, landmark.visibility] for landmark in face]).flatten())\n",
    "\n",
    "            #Row Concatenation\n",
    "            row = pose_row+face_row\n",
    "\n",
    "            #Appending the class name\n",
    "            row.insert(0, class_name)\n",
    "\n",
    "        \n",
    "            #Exporting to CSV\n",
    "            with open('coordinates1.csv', mode='a', newline='') as f:\n",
    "                csv_writer = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "                csv_writer.writerow(row)\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        cv2.imshow('Raw Webcam Feed', image)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04d8c22",
   "metadata": {},
   "source": [
    "# 3. Train Custom Model Using Scikit Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2db33b",
   "metadata": {},
   "source": [
    "## 3.1 Read in Collected Data and Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a6faa66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4a413f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('coords.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "db71f643",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>x1</th>\n",
       "      <th>y1</th>\n",
       "      <th>z1</th>\n",
       "      <th>v1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y2</th>\n",
       "      <th>z2</th>\n",
       "      <th>v2</th>\n",
       "      <th>x3</th>\n",
       "      <th>...</th>\n",
       "      <th>z499</th>\n",
       "      <th>v499</th>\n",
       "      <th>x500</th>\n",
       "      <th>y500</th>\n",
       "      <th>z500</th>\n",
       "      <th>v500</th>\n",
       "      <th>x501</th>\n",
       "      <th>y501</th>\n",
       "      <th>z501</th>\n",
       "      <th>v501</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>happy</td>\n",
       "      <td>0.490732</td>\n",
       "      <td>0.272933</td>\n",
       "      <td>-0.474348</td>\n",
       "      <td>0.999979</td>\n",
       "      <td>0.495593</td>\n",
       "      <td>0.213741</td>\n",
       "      <td>-0.429249</td>\n",
       "      <td>0.999962</td>\n",
       "      <td>0.503527</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004755</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.520493</td>\n",
       "      <td>0.218032</td>\n",
       "      <td>0.036022</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.522675</td>\n",
       "      <td>0.211355</td>\n",
       "      <td>0.038282</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>happy</td>\n",
       "      <td>0.487735</td>\n",
       "      <td>0.272730</td>\n",
       "      <td>-0.496110</td>\n",
       "      <td>0.999978</td>\n",
       "      <td>0.493273</td>\n",
       "      <td>0.213592</td>\n",
       "      <td>-0.450927</td>\n",
       "      <td>0.999961</td>\n",
       "      <td>0.501645</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005364</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.517310</td>\n",
       "      <td>0.212197</td>\n",
       "      <td>0.040008</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.519071</td>\n",
       "      <td>0.206967</td>\n",
       "      <td>0.042410</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>happy</td>\n",
       "      <td>0.487243</td>\n",
       "      <td>0.272631</td>\n",
       "      <td>-0.502617</td>\n",
       "      <td>0.999976</td>\n",
       "      <td>0.492517</td>\n",
       "      <td>0.213610</td>\n",
       "      <td>-0.456668</td>\n",
       "      <td>0.999959</td>\n",
       "      <td>0.500550</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005258</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.514932</td>\n",
       "      <td>0.210979</td>\n",
       "      <td>0.038727</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.516833</td>\n",
       "      <td>0.205957</td>\n",
       "      <td>0.041010</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>happy</td>\n",
       "      <td>0.485756</td>\n",
       "      <td>0.272154</td>\n",
       "      <td>-0.510812</td>\n",
       "      <td>0.999972</td>\n",
       "      <td>0.491084</td>\n",
       "      <td>0.213457</td>\n",
       "      <td>-0.464483</td>\n",
       "      <td>0.999953</td>\n",
       "      <td>0.499292</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005092</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.511617</td>\n",
       "      <td>0.208931</td>\n",
       "      <td>0.038353</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.513605</td>\n",
       "      <td>0.203890</td>\n",
       "      <td>0.040583</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>happy</td>\n",
       "      <td>0.483071</td>\n",
       "      <td>0.272075</td>\n",
       "      <td>-0.514905</td>\n",
       "      <td>0.999969</td>\n",
       "      <td>0.488786</td>\n",
       "      <td>0.213568</td>\n",
       "      <td>-0.469117</td>\n",
       "      <td>0.999947</td>\n",
       "      <td>0.497544</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005387</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.512617</td>\n",
       "      <td>0.210491</td>\n",
       "      <td>0.037959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.514712</td>\n",
       "      <td>0.204993</td>\n",
       "      <td>0.040172</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2005 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   class        x1        y1        z1        v1        x2        y2  \\\n",
       "0  happy  0.490732  0.272933 -0.474348  0.999979  0.495593  0.213741   \n",
       "1  happy  0.487735  0.272730 -0.496110  0.999978  0.493273  0.213592   \n",
       "2  happy  0.487243  0.272631 -0.502617  0.999976  0.492517  0.213610   \n",
       "3  happy  0.485756  0.272154 -0.510812  0.999972  0.491084  0.213457   \n",
       "4  happy  0.483071  0.272075 -0.514905  0.999969  0.488786  0.213568   \n",
       "\n",
       "         z2        v2        x3  ...      z499  v499      x500      y500  \\\n",
       "0 -0.429249  0.999962  0.503527  ...  0.004755   0.0  0.520493  0.218032   \n",
       "1 -0.450927  0.999961  0.501645  ...  0.005364   0.0  0.517310  0.212197   \n",
       "2 -0.456668  0.999959  0.500550  ...  0.005258   0.0  0.514932  0.210979   \n",
       "3 -0.464483  0.999953  0.499292  ...  0.005092   0.0  0.511617  0.208931   \n",
       "4 -0.469117  0.999947  0.497544  ...  0.005387   0.0  0.512617  0.210491   \n",
       "\n",
       "       z500  v500      x501      y501      z501  v501  \n",
       "0  0.036022   0.0  0.522675  0.211355  0.038282   0.0  \n",
       "1  0.040008   0.0  0.519071  0.206967  0.042410   0.0  \n",
       "2  0.038727   0.0  0.516833  0.205957  0.041010   0.0  \n",
       "3  0.038353   0.0  0.513605  0.203890  0.040583   0.0  \n",
       "4  0.037959   0.0  0.514712  0.204993  0.040172   0.0  \n",
       "\n",
       "[5 rows x 2005 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "876a67ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>x1</th>\n",
       "      <th>y1</th>\n",
       "      <th>z1</th>\n",
       "      <th>v1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y2</th>\n",
       "      <th>z2</th>\n",
       "      <th>v2</th>\n",
       "      <th>x3</th>\n",
       "      <th>...</th>\n",
       "      <th>z499</th>\n",
       "      <th>v499</th>\n",
       "      <th>x500</th>\n",
       "      <th>y500</th>\n",
       "      <th>z500</th>\n",
       "      <th>v500</th>\n",
       "      <th>x501</th>\n",
       "      <th>y501</th>\n",
       "      <th>z501</th>\n",
       "      <th>v501</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>happy</td>\n",
       "      <td>0.414626</td>\n",
       "      <td>0.290654</td>\n",
       "      <td>-0.485789</td>\n",
       "      <td>0.999939</td>\n",
       "      <td>0.424050</td>\n",
       "      <td>0.239975</td>\n",
       "      <td>-0.440976</td>\n",
       "      <td>0.999901</td>\n",
       "      <td>0.433081</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005777</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.461422</td>\n",
       "      <td>0.251777</td>\n",
       "      <td>0.035019</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.463738</td>\n",
       "      <td>0.245338</td>\n",
       "      <td>0.037175</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>happy</td>\n",
       "      <td>0.414989</td>\n",
       "      <td>0.289747</td>\n",
       "      <td>-0.483360</td>\n",
       "      <td>0.999941</td>\n",
       "      <td>0.424869</td>\n",
       "      <td>0.239775</td>\n",
       "      <td>-0.438355</td>\n",
       "      <td>0.999903</td>\n",
       "      <td>0.433867</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005820</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.463199</td>\n",
       "      <td>0.252491</td>\n",
       "      <td>0.035298</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.465544</td>\n",
       "      <td>0.246212</td>\n",
       "      <td>0.037456</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>happy</td>\n",
       "      <td>0.417477</td>\n",
       "      <td>0.289917</td>\n",
       "      <td>-0.484784</td>\n",
       "      <td>0.999943</td>\n",
       "      <td>0.427104</td>\n",
       "      <td>0.240534</td>\n",
       "      <td>-0.438502</td>\n",
       "      <td>0.999907</td>\n",
       "      <td>0.435881</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004931</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.464240</td>\n",
       "      <td>0.251735</td>\n",
       "      <td>0.034137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.466511</td>\n",
       "      <td>0.245513</td>\n",
       "      <td>0.036260</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>happy</td>\n",
       "      <td>0.418628</td>\n",
       "      <td>0.289750</td>\n",
       "      <td>-0.492327</td>\n",
       "      <td>0.999945</td>\n",
       "      <td>0.428738</td>\n",
       "      <td>0.240546</td>\n",
       "      <td>-0.445433</td>\n",
       "      <td>0.999910</td>\n",
       "      <td>0.437541</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006082</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.464684</td>\n",
       "      <td>0.250654</td>\n",
       "      <td>0.036471</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.466663</td>\n",
       "      <td>0.245687</td>\n",
       "      <td>0.038619</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>happy</td>\n",
       "      <td>0.418696</td>\n",
       "      <td>0.286183</td>\n",
       "      <td>-0.494264</td>\n",
       "      <td>0.999947</td>\n",
       "      <td>0.429143</td>\n",
       "      <td>0.238040</td>\n",
       "      <td>-0.448131</td>\n",
       "      <td>0.999912</td>\n",
       "      <td>0.437930</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.466521</td>\n",
       "      <td>0.249122</td>\n",
       "      <td>0.035082</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.468511</td>\n",
       "      <td>0.244277</td>\n",
       "      <td>0.037118</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2005 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     class        x1        y1        z1        v1        x2        y2  \\\n",
       "305  happy  0.414626  0.290654 -0.485789  0.999939  0.424050  0.239975   \n",
       "306  happy  0.414989  0.289747 -0.483360  0.999941  0.424869  0.239775   \n",
       "307  happy  0.417477  0.289917 -0.484784  0.999943  0.427104  0.240534   \n",
       "308  happy  0.418628  0.289750 -0.492327  0.999945  0.428738  0.240546   \n",
       "309  happy  0.418696  0.286183 -0.494264  0.999947  0.429143  0.238040   \n",
       "\n",
       "           z2        v2        x3  ...      z499  v499      x500      y500  \\\n",
       "305 -0.440976  0.999901  0.433081  ...  0.005777   0.0  0.461422  0.251777   \n",
       "306 -0.438355  0.999903  0.433867  ...  0.005820   0.0  0.463199  0.252491   \n",
       "307 -0.438502  0.999907  0.435881  ...  0.004931   0.0  0.464240  0.251735   \n",
       "308 -0.445433  0.999910  0.437541  ...  0.006082   0.0  0.464684  0.250654   \n",
       "309 -0.448131  0.999912  0.437930  ...  0.005135   0.0  0.466521  0.249122   \n",
       "\n",
       "         z500  v500      x501      y501      z501  v501  \n",
       "305  0.035019   0.0  0.463738  0.245338  0.037175   0.0  \n",
       "306  0.035298   0.0  0.465544  0.246212  0.037456   0.0  \n",
       "307  0.034137   0.0  0.466511  0.245513  0.036260   0.0  \n",
       "308  0.036471   0.0  0.466663  0.245687  0.038619   0.0  \n",
       "309  0.035082   0.0  0.468511  0.244277  0.037118   0.0  \n",
       "\n",
       "[5 rows x 2005 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "83fa8ce4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>x1</th>\n",
       "      <th>y1</th>\n",
       "      <th>z1</th>\n",
       "      <th>v1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y2</th>\n",
       "      <th>z2</th>\n",
       "      <th>v2</th>\n",
       "      <th>x3</th>\n",
       "      <th>...</th>\n",
       "      <th>z499</th>\n",
       "      <th>v499</th>\n",
       "      <th>x500</th>\n",
       "      <th>y500</th>\n",
       "      <th>z500</th>\n",
       "      <th>v500</th>\n",
       "      <th>x501</th>\n",
       "      <th>y501</th>\n",
       "      <th>z501</th>\n",
       "      <th>v501</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 2005 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [class, x1, y1, z1, v1, x2, y2, z2, v2, x3, y3, z3, v3, x4, y4, z4, v4, x5, y5, z5, v5, x6, y6, z6, v6, x7, y7, z7, v7, x8, y8, z8, v8, x9, y9, z9, v9, x10, y10, z10, v10, x11, y11, z11, v11, x12, y12, z12, v12, x13, y13, z13, v13, x14, y14, z14, v14, x15, y15, z15, v15, x16, y16, z16, v16, x17, y17, z17, v17, x18, y18, z18, v18, x19, y19, z19, v19, x20, y20, z20, v20, x21, y21, z21, v21, x22, y22, z22, v22, x23, y23, z23, v23, x24, y24, z24, v24, x25, y25, z25, ...]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 2005 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['class']=='Sad']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f383701a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('class', axis=1) # features\n",
    "y = df['class'] # target value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0bb6054d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "43e5055f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179    happy\n",
       "221    happy\n",
       "219    happy\n",
       "257    happy\n",
       "248    happy\n",
       "       ...  \n",
       "165    happy\n",
       "186    happy\n",
       "182    happy\n",
       "115    happy\n",
       "242    happy\n",
       "Name: class, Length: 93, dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49aba478",
   "metadata": {},
   "source": [
    "## 3.2 Train Machine Learning Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d7c723da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline \n",
    "from sklearn.preprocessing import StandardScaler \n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4d4f3229",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelines = {\n",
    "    'lr':make_pipeline(StandardScaler(), LogisticRegression()),\n",
    "    'rc':make_pipeline(StandardScaler(), RidgeClassifier()),\n",
    "    'rf':make_pipeline(StandardScaler(), RandomForestClassifier()),\n",
    "    'gb':make_pipeline(StandardScaler(), GradientBoostingClassifier()),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c86e7d51",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "This solver needs samples of at least 2 classes in the data, but the data contains only one class: 'happy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m fit_models \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m algo, pipeline \u001b[38;5;129;01min\u001b[39;00m pipelines\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m----> 3\u001b[0m     model \u001b[38;5;241m=\u001b[39m pipeline\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[1;32m      4\u001b[0m     fit_models[algo] \u001b[38;5;241m=\u001b[39m model\n",
      "File \u001b[0;32m/opt/anaconda3/envs/dnn/lib/python3.12/site-packages/sklearn/base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1387\u001b[0m     )\n\u001b[1;32m   1388\u001b[0m ):\n\u001b[0;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/dnn/lib/python3.12/site-packages/sklearn/pipeline.py:662\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m    656\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    657\u001b[0m         last_step_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_metadata_for_step(\n\u001b[1;32m    658\u001b[0m             step_idx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m    659\u001b[0m             step_params\u001b[38;5;241m=\u001b[39mrouted_params[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m]],\n\u001b[1;32m    660\u001b[0m             all_params\u001b[38;5;241m=\u001b[39mparams,\n\u001b[1;32m    661\u001b[0m         )\n\u001b[0;32m--> 662\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator\u001b[38;5;241m.\u001b[39mfit(Xt, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mlast_step_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    664\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/dnn/lib/python3.12/site-packages/sklearn/base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1387\u001b[0m     )\n\u001b[1;32m   1388\u001b[0m ):\n\u001b[0;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/dnn/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1301\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1299\u001b[0m classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\n\u001b[1;32m   1300\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_classes \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m-> 1301\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1302\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis solver needs samples of at least 2 classes\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1303\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m in the data, but the data contains only one\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1304\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m class: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m classes_[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1305\u001b[0m     )\n\u001b[1;32m   1307\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m   1308\u001b[0m     n_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mValueError\u001b[0m: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 'happy'"
     ]
    }
   ],
   "source": [
    "fit_models = {}\n",
    "for algo, pipeline in pipelines.items():\n",
    "    model = pipeline.fit(X_train, y_train)\n",
    "    fit_models[algo] = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a196b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1553efe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_models['rc'].predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9867f0e2",
   "metadata": {},
   "source": [
    "## 3.3 Evaluate and Serialize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e8d9d582",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score # Accuracy metrics \n",
    "import pickle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2c21a7a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr 1.0\n",
      "rc 1.0\n",
      "rf 0.9960212201591512\n",
      "gb 0.9986737400530504\n"
     ]
    }
   ],
   "source": [
    "for algo, model in fit_models.items():\n",
    "    yhat = model.predict(X_test)\n",
    "    print(algo, accuracy_score(y_test, yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "976fc2d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['sad', 'sad', 'happy', 'sad', 'happy', 'happy', 'happy', 'happy',\n",
       "       'sad', 'victorious ', 'happy', 'sad', 'sad', 'sad', 'victorious ',\n",
       "       'happy', 'happy', 'victorious ', 'sad', 'happy', 'sad',\n",
       "       'victorious ', 'happy', 'sad', 'sad', 'sad', 'sad', 'sad',\n",
       "       'victorious ', 'victorious ', 'sad', 'victorious ', 'sad', 'sad',\n",
       "       'happy', 'sad', 'victorious ', 'sad', 'sad', 'sad', 'victorious ',\n",
       "       'happy', 'happy', 'happy', 'victorious ', 'victorious ', 'sad',\n",
       "       'victorious ', 'happy', 'victorious ', 'sad', 'sad', 'happy',\n",
       "       'happy', 'happy', 'sad', 'sad', 'sad', 'happy', 'victorious ',\n",
       "       'sad', 'happy', 'happy', 'sad', 'happy', 'happy', 'victorious ',\n",
       "       'sad', 'happy', 'victorious ', 'happy', 'happy', 'victorious ',\n",
       "       'happy', 'sad', 'happy', 'sad', 'happy', 'victorious ', 'happy',\n",
       "       'happy', 'victorious ', 'happy', 'victorious ', 'happy', 'happy',\n",
       "       'victorious ', 'victorious ', 'happy', 'sad', 'sad', 'victorious ',\n",
       "       'sad', 'sad', 'happy', 'victorious ', 'victorious ', 'happy',\n",
       "       'sad', 'happy', 'sad', 'sad', 'happy', 'happy', 'sad', 'happy',\n",
       "       'victorious ', 'sad', 'sad', 'happy', 'victorious ', 'sad', 'sad',\n",
       "       'happy', 'happy', 'sad', 'happy', 'happy', 'sad', 'happy', 'happy',\n",
       "       'sad', 'sad', 'happy', 'victorious ', 'victorious ', 'victorious ',\n",
       "       'sad', 'sad', 'happy', 'happy', 'victorious ', 'happy',\n",
       "       'victorious ', 'victorious ', 'sad', 'victorious ', 'happy',\n",
       "       'happy', 'happy', 'sad', 'happy', 'sad', 'sad', 'victorious ',\n",
       "       'happy', 'happy', 'sad', 'happy', 'happy', 'sad', 'victorious ',\n",
       "       'sad', 'happy', 'sad', 'victorious ', 'sad', 'happy', 'happy',\n",
       "       'happy', 'sad', 'happy', 'happy', 'victorious ', 'happy', 'happy',\n",
       "       'sad', 'sad', 'happy', 'sad', 'happy', 'sad', 'sad', 'sad',\n",
       "       'victorious ', 'sad', 'sad', 'happy', 'sad', 'sad', 'victorious ',\n",
       "       'sad', 'sad', 'sad', 'sad', 'happy', 'victorious ', 'sad', 'happy',\n",
       "       'victorious ', 'happy', 'happy', 'sad', 'victorious ', 'happy',\n",
       "       'happy', 'sad', 'sad', 'happy', 'happy', 'happy', 'happy',\n",
       "       'victorious ', 'sad', 'sad', 'victorious ', 'sad', 'sad', 'sad',\n",
       "       'sad', 'sad', 'happy', 'sad', 'sad', 'sad', 'happy', 'victorious ',\n",
       "       'sad', 'happy', 'happy', 'happy', 'victorious ', 'happy', 'sad',\n",
       "       'victorious ', 'sad', 'happy', 'victorious ', 'happy', 'happy',\n",
       "       'happy', 'victorious ', 'happy', 'victorious ', 'sad', 'happy',\n",
       "       'happy', 'happy', 'sad', 'sad', 'happy', 'sad', 'happy', 'sad',\n",
       "       'victorious ', 'sad', 'sad', 'sad', 'sad', 'victorious ', 'happy',\n",
       "       'happy', 'happy', 'happy', 'victorious ', 'sad', 'victorious ',\n",
       "       'sad', 'victorious ', 'sad', 'happy', 'sad', 'happy', 'happy',\n",
       "       'sad', 'happy', 'happy', 'sad', 'happy', 'happy', 'sad', 'sad',\n",
       "       'victorious ', 'victorious ', 'victorious ', 'happy', 'sad',\n",
       "       'happy', 'victorious ', 'victorious ', 'sad', 'sad', 'happy',\n",
       "       'happy', 'happy', 'sad', 'sad', 'happy', 'sad', 'sad', 'happy',\n",
       "       'sad', 'sad', 'happy', 'victorious ', 'victorious ', 'happy',\n",
       "       'victorious ', 'sad', 'happy', 'happy', 'happy', 'happy', 'sad',\n",
       "       'sad', 'happy', 'sad', 'sad', 'victorious ', 'happy', 'happy',\n",
       "       'victorious ', 'happy', 'sad', 'happy', 'sad', 'victorious ',\n",
       "       'sad', 'happy', 'sad', 'sad', 'happy', 'sad', 'sad', 'sad', 'sad',\n",
       "       'sad', 'happy', 'happy', 'victorious ', 'happy', 'sad',\n",
       "       'victorious ', 'happy', 'victorious ', 'sad', 'sad', 'sad',\n",
       "       'victorious ', 'victorious ', 'sad', 'sad', 'sad', 'victorious ',\n",
       "       'victorious ', 'victorious ', 'happy', 'victorious ', 'happy',\n",
       "       'victorious ', 'happy', 'happy', 'victorious ', 'victorious ',\n",
       "       'victorious ', 'sad', 'happy', 'sad', 'sad', 'sad', 'happy',\n",
       "       'happy', 'sad', 'victorious ', 'victorious ', 'sad', 'victorious ',\n",
       "       'happy', 'victorious ', 'sad', 'happy', 'victorious ', 'sad',\n",
       "       'sad', 'happy', 'happy', 'sad', 'sad', 'sad', 'victorious ',\n",
       "       'victorious ', 'happy', 'sad', 'sad', 'happy', 'victorious ',\n",
       "       'happy', 'victorious ', 'victorious ', 'sad', 'happy', 'sad',\n",
       "       'happy', 'happy', 'happy', 'happy', 'sad', 'happy', 'happy',\n",
       "       'happy', 'happy', 'sad', 'happy', 'victorious ', 'sad', 'happy',\n",
       "       'happy', 'happy', 'victorious ', 'happy', 'happy', 'victorious ',\n",
       "       'victorious ', 'victorious ', 'happy', 'victorious ', 'sad', 'sad',\n",
       "       'sad', 'sad', 'happy', 'sad', 'happy', 'sad', 'sad', 'victorious ',\n",
       "       'happy', 'sad', 'sad', 'sad', 'happy', 'happy', 'sad',\n",
       "       'victorious ', 'victorious ', 'happy', 'happy', 'sad', 'sad',\n",
       "       'victorious ', 'happy', 'happy', 'victorious ', 'sad', 'happy',\n",
       "       'happy', 'sad', 'happy', 'happy', 'happy', 'victorious ', 'sad',\n",
       "       'happy', 'sad', 'happy', 'victorious ', 'victorious ', 'happy',\n",
       "       'happy', 'sad', 'happy', 'victorious ', 'victorious ',\n",
       "       'victorious ', 'victorious ', 'happy', 'victorious ', 'happy',\n",
       "       'sad', 'sad', 'sad', 'sad', 'sad', 'victorious ', 'sad', 'happy',\n",
       "       'happy', 'happy', 'victorious ', 'sad', 'happy', 'happy', 'happy',\n",
       "       'happy', 'victorious ', 'happy', 'happy', 'happy', 'victorious ',\n",
       "       'happy', 'sad', 'happy', 'happy', 'sad', 'victorious ', 'happy',\n",
       "       'sad', 'happy', 'happy', 'sad', 'sad', 'sad', 'happy',\n",
       "       'victorious ', 'sad', 'sad', 'victorious ', 'happy', 'victorious ',\n",
       "       'victorious ', 'sad', 'sad', 'sad', 'sad', 'happy', 'happy',\n",
       "       'happy', 'sad', 'happy', 'victorious ', 'victorious ', 'happy',\n",
       "       'sad', 'happy', 'happy', 'happy', 'victorious ', 'happy', 'happy',\n",
       "       'happy', 'victorious ', 'happy', 'happy', 'sad', 'sad', 'happy',\n",
       "       'victorious ', 'happy', 'happy', 'happy', 'happy', 'happy', 'sad',\n",
       "       'happy', 'sad', 'victorious ', 'sad', 'sad', 'happy', 'happy',\n",
       "       'victorious ', 'sad', 'victorious ', 'sad', 'sad', 'sad', 'sad',\n",
       "       'sad', 'happy', 'sad', 'happy', 'sad', 'happy', 'victorious ',\n",
       "       'happy', 'happy', 'sad', 'sad', 'victorious ', 'victorious ',\n",
       "       'sad', 'happy', 'victorious ', 'victorious ', 'victorious ',\n",
       "       'victorious ', 'sad', 'victorious ', 'happy', 'sad', 'victorious ',\n",
       "       'victorious ', 'sad', 'happy', 'happy', 'victorious ', 'sad',\n",
       "       'happy', 'sad', 'victorious ', 'sad', 'happy', 'victorious ',\n",
       "       'sad', 'happy', 'victorious ', 'sad', 'victorious ', 'happy',\n",
       "       'happy', 'victorious ', 'sad', 'sad', 'happy', 'victorious ',\n",
       "       'happy', 'happy', 'victorious ', 'sad', 'victorious ', 'happy',\n",
       "       'happy', 'victorious ', 'victorious ', 'happy', 'sad', 'happy',\n",
       "       'victorious ', 'happy', 'victorious ', 'sad', 'victorious ', 'sad',\n",
       "       'happy', 'sad', 'sad', 'sad', 'sad', 'victorious ', 'happy',\n",
       "       'victorious ', 'happy', 'sad', 'victorious ', 'happy', 'sad',\n",
       "       'sad', 'happy', 'sad', 'sad', 'happy', 'sad', 'sad', 'happy',\n",
       "       'victorious ', 'victorious ', 'sad', 'sad', 'happy', 'sad',\n",
       "       'victorious ', 'happy', 'victorious ', 'sad', 'happy', 'sad',\n",
       "       'happy', 'sad', 'sad', 'victorious ', 'victorious ', 'sad',\n",
       "       'happy', 'happy', 'sad', 'sad', 'happy', 'victorious ', 'happy',\n",
       "       'happy', 'victorious ', 'sad', 'victorious ', 'happy', 'sad',\n",
       "       'victorious ', 'happy', 'victorious ', 'sad', 'happy',\n",
       "       'victorious ', 'happy', 'happy', 'happy', 'victorious ',\n",
       "       'victorious ', 'happy', 'happy', 'sad', 'happy', 'happy', 'sad',\n",
       "       'sad', 'sad', 'sad', 'sad', 'sad', 'victorious ', 'happy', 'sad',\n",
       "       'victorious ', 'happy', 'happy', 'sad', 'happy', 'victorious ',\n",
       "       'victorious ', 'victorious ', 'happy', 'victorious ', 'happy',\n",
       "       'sad', 'sad', 'victorious ', 'victorious ', 'happy', 'sad', 'sad',\n",
       "       'sad', 'happy', 'happy', 'sad', 'victorious ', 'sad',\n",
       "       'victorious ', 'victorious ', 'victorious ', 'victorious ', 'sad',\n",
       "       'sad', 'happy', 'victorious ', 'sad', 'happy', 'victorious ',\n",
       "       'victorious ', 'sad', 'happy', 'sad', 'victorious ', 'victorious ',\n",
       "       'sad', 'happy', 'victorious ', 'victorious ', 'happy', 'sad',\n",
       "       'victorious ', 'sad', 'sad', 'sad', 'happy', 'sad', 'happy'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_models['rf'].predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "1a3e654b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1935      sad\n",
       "1916      sad\n",
       "2226    happy\n",
       "732       sad\n",
       "381     happy\n",
       "        ...  \n",
       "486       sad\n",
       "510       sad\n",
       "87      happy\n",
       "1728      sad\n",
       "2374    happy\n",
       "Name: class, Length: 754, dtype: object"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "9813abe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('body_language.pkl', 'wb') as f:\n",
    "    pickle.dump(fit_models['rf'], f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a3ae064",
   "metadata": {},
   "source": [
    "# 4. Make Detections with Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "cea3da53",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('body_language.pkl', 'rb') as f:\n",
    "    model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "51bc58e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                ('randomforestclassifier', RandomForestClassifier())])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "4cb9412a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "happy [0.46 0.37 0.17]\n",
      "happy [0.8  0.03 0.17]\n",
      "happy [0.71 0.   0.29]\n",
      "happy [0.78 0.   0.22]\n",
      "happy [0.69 0.   0.31]\n",
      "happy [0.58 0.   0.42]\n",
      "happy [0.54 0.   0.46]\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "# Initiate holistic model\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        # Recolor Feed\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False        \n",
    "        \n",
    "        # Make Detections\n",
    "        results = holistic.process(image)\n",
    "        # print(results.face_landmarks)\n",
    "        \n",
    "        # face_landmarks, pose_landmarks, left_hand_landmarks, right_hand_landmarks\n",
    "        \n",
    "        # Recolor image back to BGR for rendering\n",
    "        image.flags.writeable = True   \n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        # 1. Draw face landmarks\n",
    "        mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACEMESH_CONTOURS, \n",
    "                                 mp_drawing.DrawingSpec(color=(80,110,10), thickness=1, circle_radius=1),\n",
    "                                 mp_drawing.DrawingSpec(color=(80,256,121), thickness=1, circle_radius=1)\n",
    "                                 )\n",
    "        \n",
    "        # 2. Right hand\n",
    "        mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                                 mp_drawing.DrawingSpec(color=(80,22,10), thickness=2, circle_radius=4),\n",
    "                                 mp_drawing.DrawingSpec(color=(80,44,121), thickness=2, circle_radius=2)\n",
    "                                 )\n",
    "\n",
    "        # 3. Left Hand\n",
    "        mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                                 mp_drawing.DrawingSpec(color=(121,22,76), thickness=2, circle_radius=4),\n",
    "                                 mp_drawing.DrawingSpec(color=(121,44,250), thickness=2, circle_radius=2)\n",
    "                                 )\n",
    "\n",
    "        # 4. Pose Detections\n",
    "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS, \n",
    "                                 mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=4),\n",
    "                                 mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)\n",
    "                                 )\n",
    "        # Export coordinates\n",
    "        try:\n",
    "            # Extract Pose landmarks\n",
    "            pose = results.pose_landmarks.landmark\n",
    "            pose_row = list(np.array([[landmark.x, landmark.y, landmark.z, landmark.visibility] for landmark in pose]).flatten())\n",
    "            \n",
    "            # Extract Face landmarks\n",
    "            face = results.face_landmarks.landmark\n",
    "            face_row = list(np.array([[landmark.x, landmark.y, landmark.z, landmark.visibility] for landmark in face]).flatten())\n",
    "            \n",
    "            # Concate rows\n",
    "            row = pose_row+face_row\n",
    "            \n",
    "#             # Append class name \n",
    "#             row.insert(0, class_name)\n",
    "            \n",
    "#             # Export to CSV\n",
    "#             with open('coords.csv', mode='a', newline='') as f:\n",
    "#                 csv_writer = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "#                 csv_writer.writerow(row) \n",
    "\n",
    "            # Make Detections\n",
    "            X = pd.DataFrame([row])\n",
    "            body_language_class = model.predict(X)[0]\n",
    "            body_language_prob = model.predict_proba(X)[0]\n",
    "            print(body_language_class, body_language_prob)\n",
    "            \n",
    "            # Grab ear coords\n",
    "            coords = tuple(np.multiply(\n",
    "                            np.array(\n",
    "                                (results.pose_landmarks.landmark[mp_holistic.PoseLandmark.LEFT_EAR].x, \n",
    "                                 results.pose_landmarks.landmark[mp_holistic.PoseLandmark.LEFT_EAR].y))\n",
    "                        , [640,480]).astype(int))\n",
    "            \n",
    "            cv2.rectangle(image, \n",
    "                          (coords[0], coords[1]+5), \n",
    "                          (coords[0]+len(body_language_class)*20, coords[1]-30), \n",
    "                          (245, 117, 16), -1)\n",
    "            cv2.putText(image, body_language_class, coords, \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "            \n",
    "            # Get status box\n",
    "            cv2.rectangle(image, (0,0), (250, 60), (245, 117, 16), -1)\n",
    "            \n",
    "            # Display Class\n",
    "            cv2.putText(image, 'CLASS'\n",
    "                        , (95,12), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1, cv2.LINE_AA)\n",
    "            cv2.putText(image, body_language_class.split(' ')[0]\n",
    "                        , (90,40), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "            \n",
    "            # Display Probability\n",
    "            cv2.putText(image, 'PROB'\n",
    "                        , (15,12), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1, cv2.LINE_AA)\n",
    "            cv2.putText(image, str(round(body_language_prob[np.argmax(body_language_prob)],2))\n",
    "                        , (10,40), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "            \n",
    "        except:\n",
    "            pass\n",
    "                        \n",
    "        cv2.imshow('Raw Webcam Feed', image)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "877fb7fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(431, 181)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuple(np.multiply(np.array((results.pose_landmarks.landmark[mp_holistic.PoseLandmark.LEFT_EAR].x, \n",
    "results.pose_landmarks.landmark[mp_holistic.PoseLandmark.LEFT_EAR].y)), [640,480]).astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f781462c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec04303",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
